{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89407e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fb4b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 3072\n",
    "D_in = input_size\n",
    "H = 50\n",
    "D_out = 10\n",
    "num_epochs = 10\n",
    "transformation = transforms.Compose( [transforms.Resize((32,32)), \n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                                          std=[0.5, 0.5, 0.5])])\n",
    "training_set = torchvision.datasets.ImageFolder('/Users/jgold/Documents/GitHub/Artifical-Intelligence-Project/TrainSet', \n",
    "                                                transform=transformation)\n",
    "                                                \n",
    "train_loader = torch.utils.data.DataLoader(training_set, batch_size=100, shuffle=True, num_workers=2)\n",
    "testing_set = torchvision.datasets.ImageFolder('/Users/jgold/Documents/GitHub/Artifical-Intelligence-Project/TestSet', transform=transformation)\n",
    "test_loader = torch.utils.data.DataLoader(training_set, batch_size=100, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875c1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as td\n",
    "\n",
    "class MultiLayerFCNet(nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(MultiLayerFCNet, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, H)\n",
    "        self.linear3 = torch.nn.Linear(H, H)\n",
    "        self.linear4 = torch.nn.Linear(H, D_out)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = F.relu(self.linear3(x))\n",
    "        x = self.linear4(x)\n",
    "        return F.log_softmax(x,dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aab335fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiLayerFCNet(D_in, H, D_out)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70f2bea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2698]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2680]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2694]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2620]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2540]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2485]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2470]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2403]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2358]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2286]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2196]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.2104]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.1993]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.1889]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.1770]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.1650]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.1540]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.1408]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.1238]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.1078]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.0943]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.0806]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.0637]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.0525]\n",
      "Epoch [1/10], Averge Loss:for epoch[1, 2.0263]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.6392]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.6886]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.6279]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.6135]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.6030]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.5996]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.5893]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.5760]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.5700]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.5640]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.5422]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.5283]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.5107]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.5040]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4865]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4816]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4718]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4641]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4553]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4426]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4349]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4251]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4166]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4126]\n",
      "Epoch [2/10], Averge Loss:for epoch[2, 1.4149]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1563]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1494]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1711]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1952]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.2046]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1784]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1725]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1765]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1683]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1655]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1617]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1486]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1479]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1446]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1495]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1428]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1428]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1421]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1461]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1444]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1407]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1398]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1376]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1401]\n",
      "Epoch [3/10], Averge Loss:for epoch[3, 1.1311]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9520]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9292]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9693]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9786]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9762]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9810]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9803]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9858]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9882]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9825]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9762]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9782]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9780]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9758]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9752]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9755]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9777]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9832]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9819]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9872]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9931]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9971]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9935]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9917]\n",
      "Epoch [4/10], Averge Loss:for epoch[4, 0.9876]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9059]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9249]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9462]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9481]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9419]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9142]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9276]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9196]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9164]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9147]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9224]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9215]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9297]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9280]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9152]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9171]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9126]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9104]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9048]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9069]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9010]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9045]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9012]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9000]\n",
      "Epoch [5/10], Averge Loss:for epoch[5, 0.9144]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.9229]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8803]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.9021]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.9033]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8942]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8929]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8998]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8855]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8870]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8860]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8795]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8745]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8697]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8631]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8649]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8651]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8699]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8661]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8612]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8559]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8586]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8545]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8500]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8518]\n",
      "Epoch [6/10], Averge Loss:for epoch[6, 0.8438]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.7229]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8023]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8529]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8401]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8122]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8079]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8035]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.7947]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.7923]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.7913]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.7939]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.7907]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8083]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8121]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8132]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8154]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8145]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8145]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8154]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8119]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8095]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8054]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8053]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.8013]\n",
      "Epoch [7/10], Averge Loss:for epoch[7, 0.7898]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.8525]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7697]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7682]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7677]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7743]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7614]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7461]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7583]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7641]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7468]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7401]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7408]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7455]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7497]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7529]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7524]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7513]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7612]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7670]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7615]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7675]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7644]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7660]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7664]\n",
      "Epoch [8/10], Averge Loss:for epoch[8, 0.7798]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.8927]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7862]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7737]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7505]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7515]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7646]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7470]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7616]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7533]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7610]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7588]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7603]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7705]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7764]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7818]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7840]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7761]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7780]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7777]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7843]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7903]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7859]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7855]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7920]\n",
      "Epoch [9/10], Averge Loss:for epoch[9, 0.7925]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.9228]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.8386]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7669]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7676]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7606]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7848]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7960]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7931]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7821]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7723]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7677]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7535]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7503]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7613]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7519]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7594]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7590]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7535]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7524]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7548]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7562]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7556]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7541]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7505]\n",
      "Epoch [10/10], Averge Loss:for epoch[10, 0.7443]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    avg_loss_epoch = 0\n",
    "    batch_loss = 0\n",
    "    total_batches = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 32 * 32 * 3)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_batches += 1\n",
    "        batch_loss += loss.item()\n",
    "        avg_loss_epoch = batch_loss / total_batches\n",
    "        print('Epoch [{}/{}], Averge Loss:for epoch[{}, {:.4f}]'\n",
    "        .format(epoch + 1, num_epochs, epoch + 1, avg_loss_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5662ce58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 1900 test images: 74 %\n",
      "Accuracy of the network on the 1900 test images: 71 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 73 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 71 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 72 %\n",
      "Accuracy of the network on the 1900 test images: 71 %\n",
      "Accuracy of the network on the 1900 test images: 71 %\n",
      "Accuracy of the network on the 1900 test images: 71 %\n",
      "Accuracy of the network on the 1900 test images: 71 %\n",
      "Accuracy of the network on the 1900 test images: 71 %\n",
      "Accuracy of the network on the 1900 test images: 71 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.reshape(-1, 3 * 32 * 32)\n",
    "    outputs_test = model(images)\n",
    "    _, predicted = torch.max(outputs_test.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 1900 test images: %d %%'\n",
    "    % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d330d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.LeakyReLU(inplace=True),\n",
    "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(32),\n",
    "        nn.LeakyReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(inplace=True),\n",
    "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "        nn.BatchNorm2d(64),\n",
    "        nn.LeakyReLU(inplace=True),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(8 * 8 * 64, 1000),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Linear(1000, 512),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(512, 10)\n",
    "    )\n",
    "    def forward(self, x):\n",
    "        # conv layers\n",
    "        x = self.conv_layer(x)\n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # fc layer\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "740cefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "num_classes = 4\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ddfeea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c234cbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/4], Step [1/25], Loss: 0.0317, Accuracy: 99.00%\n",
      "Epoch [1/4], Step [2/25], Loss: 0.0361, Accuracy: 99.00%\n",
      "Epoch [1/4], Step [3/25], Loss: 0.0410, Accuracy: 99.00%\n",
      "Epoch [1/4], Step [4/25], Loss: 0.0158, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [5/25], Loss: 0.0151, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [6/25], Loss: 0.0230, Accuracy: 99.00%\n",
      "Epoch [1/4], Step [7/25], Loss: 0.0059, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [8/25], Loss: 0.0061, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [9/25], Loss: 0.0150, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [10/25], Loss: 0.0059, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [11/25], Loss: 0.0119, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [12/25], Loss: 0.0082, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [13/25], Loss: 0.0363, Accuracy: 99.00%\n",
      "Epoch [1/4], Step [14/25], Loss: 0.0103, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [15/25], Loss: 0.0058, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [16/25], Loss: 0.0076, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [17/25], Loss: 0.0108, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [18/25], Loss: 0.0099, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [19/25], Loss: 0.0128, Accuracy: 99.00%\n",
      "Epoch [1/4], Step [20/25], Loss: 0.0433, Accuracy: 98.00%\n",
      "Epoch [1/4], Step [21/25], Loss: 0.0877, Accuracy: 97.00%\n",
      "Epoch [1/4], Step [22/25], Loss: 0.0233, Accuracy: 99.00%\n",
      "Epoch [1/4], Step [23/25], Loss: 0.0101, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [24/25], Loss: 0.0063, Accuracy: 100.00%\n",
      "Epoch [1/4], Step [25/25], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [1/25], Loss: 0.0056, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [2/25], Loss: 0.0086, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [3/25], Loss: 0.0043, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [4/25], Loss: 0.0076, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [5/25], Loss: 0.0112, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [6/25], Loss: 0.0049, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [7/25], Loss: 0.0091, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [8/25], Loss: 0.0092, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [9/25], Loss: 0.0055, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [10/25], Loss: 0.0065, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [11/25], Loss: 0.0313, Accuracy: 98.00%\n",
      "Epoch [2/4], Step [12/25], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [13/25], Loss: 0.0020, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [14/25], Loss: 0.0052, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [15/25], Loss: 0.0226, Accuracy: 99.00%\n",
      "Epoch [2/4], Step [16/25], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [17/25], Loss: 0.0032, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [18/25], Loss: 0.0039, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [19/25], Loss: 0.0244, Accuracy: 99.00%\n",
      "Epoch [2/4], Step [20/25], Loss: 0.0060, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [21/25], Loss: 0.0076, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [22/25], Loss: 0.0030, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [23/25], Loss: 0.0041, Accuracy: 100.00%\n",
      "Epoch [2/4], Step [24/25], Loss: 0.0121, Accuracy: 99.00%\n",
      "Epoch [2/4], Step [25/25], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [1/25], Loss: 0.0022, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [2/25], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [3/25], Loss: 0.0061, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [4/25], Loss: 0.0011, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [5/25], Loss: 0.0002, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [6/25], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [7/25], Loss: 0.0099, Accuracy: 99.00%\n",
      "Epoch [3/4], Step [8/25], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [9/25], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [10/25], Loss: 0.0120, Accuracy: 99.00%\n",
      "Epoch [3/4], Step [11/25], Loss: 0.0035, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [12/25], Loss: 0.0024, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [13/25], Loss: 0.0016, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [14/25], Loss: 0.0070, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [15/25], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [16/25], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [17/25], Loss: 0.0254, Accuracy: 99.00%\n",
      "Epoch [3/4], Step [18/25], Loss: 0.0006, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [19/25], Loss: 0.0026, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [20/25], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [21/25], Loss: 0.0010, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [22/25], Loss: 0.0014, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [23/25], Loss: 0.0396, Accuracy: 99.00%\n",
      "Epoch [3/4], Step [24/25], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [3/4], Step [25/25], Loss: 0.0019, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [1/25], Loss: 0.0025, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [2/25], Loss: 0.0044, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [3/25], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [4/25], Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [5/25], Loss: 0.0082, Accuracy: 99.00%\n",
      "Epoch [4/4], Step [6/25], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [7/25], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [8/25], Loss: 0.0029, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [9/25], Loss: 0.0765, Accuracy: 98.00%\n",
      "Epoch [4/4], Step [10/25], Loss: 0.0007, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [11/25], Loss: 0.0015, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [12/25], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [13/25], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [14/25], Loss: 0.0036, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [15/25], Loss: 0.0009, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [16/25], Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [17/25], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [18/25], Loss: 0.0005, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [19/25], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [20/25], Loss: 0.0008, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [21/25], Loss: 0.0023, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [22/25], Loss: 0.0004, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [23/25], Loss: 0.0003, Accuracy: 100.00%\n",
      "Epoch [4/4], Step [24/25], Loss: 0.0207, Accuracy: 99.00%\n",
      "Epoch [4/4], Step [25/25], Loss: 0.0001, Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_list.append(loss.item())\n",
    "        # Backprop and optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Train accuracy\n",
    "        total = labels.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        acc_list.append(correct / total)\n",
    "        print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
    "             .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(),\n",
    "             (correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "abc6ce25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 1900 test images: 69.0 %\n",
      "Test Accuracy of the model on the 1900 test images: 72.5 %\n",
      "Test Accuracy of the model on the 1900 test images: 70.0 %\n",
      "Test Accuracy of the model on the 1900 test images: 72.5 %\n",
      "Test Accuracy of the model on the 1900 test images: 72.8 %\n",
      "Test Accuracy of the model on the 1900 test images: 73.33333333333333 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.85714285714286 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.75 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.44444444444444 %\n",
      "Test Accuracy of the model on the 1900 test images: 73.8 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.0 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.0 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.0 %\n",
      "Test Accuracy of the model on the 1900 test images: 73.64285714285714 %\n",
      "Test Accuracy of the model on the 1900 test images: 73.93333333333332 %\n",
      "Test Accuracy of the model on the 1900 test images: 73.9375 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.3529411764706 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.72222222222223 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.47368421052632 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.95 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.61904761904762 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.86363636363636 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.95652173913044 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.83333333333333 %\n",
      "Test Accuracy of the model on the 1900 test images: 74.72118959107806 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        print('Test Accuracy of the model on the 1900 test images: {} %'\n",
    "          .format((correct / total) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97cb7e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.65      0.68       452\n",
      "           1       0.55      0.75      0.64       541\n",
      "           2       0.91      0.89      0.90       515\n",
      "           3       0.84      0.71      0.77       913\n",
      "\n",
      "    accuracy                           0.75      2421\n",
      "   macro avg       0.76      0.75      0.75      2421\n",
      "weighted avg       0.77      0.75      0.75      2421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "model.eval()\n",
    "prediction_list = []\n",
    "accurate_list = []\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(model(images), 1)\n",
    "        prediction_list.extend(predicted.detach().cpu().numpy())\n",
    "        accurate_list.extend(labels.detach().cpu().numpy())\n",
    "  \n",
    "  \n",
    "confusion_matrix_data = confusion_matrix(accurate_list, prediction_list)\n",
    "confusionMatrix = sns.heatmap(confusion_matrix_data, annot=True, fmt='g' )\n",
    "confusionMatrix.set_title('Confusion Matrix');\n",
    "confusionMatrix.set_xlabel('Predicted Categories')\n",
    "confusionMatrix.set_ylabel('Actual Categories');\n",
    "confusionMatrix.xaxis.set_ticklabels(['Cloth Mask','N95','No Mask','Surgical Mask'])\n",
    "confusionMatrix.yaxis.set_ticklabels(['Cloth Mask','N95','No Mask','Surgical Mask'])\n",
    "\n",
    "  \n",
    "plt.show()\n",
    "\n",
    "print(classification_report(prediction_list, accurate_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be4cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
